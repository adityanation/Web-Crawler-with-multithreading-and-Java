Overview
This is a multithreaded web crawler built using Java. The crawler efficiently traverses web pages, extracts URLs, and downloads content while leveraging multithreading to improve performance.

Features
Multithreading Support: Uses Java's concurrency features to crawl multiple pages simultaneously.
URL Filtering: Avoids duplicate links and restricts crawling to specified domains.
Customizable Depth: Allows setting the depth of crawling to control recursion levels.
Content Extraction: Can extract text, metadata, and hyperlinks from crawled pages.
Politeness Policy: Implements delays between requests to avoid overloading servers.

